{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55beb429",
   "metadata": {},
   "source": [
    "## Binary Classification Example: Breast Cancer Wisconsin Data\n",
    "\n",
    "This dataset is concerned with predicting whether a cell tissue is cancerous or not using the cell's measurement values. It contains 569 observations and 30 input features. The target feature, \"diagnosis\", has two classes: 212 \"malignant\" and 357 \"benign\", denoted by \"M\" and \"B\" respectively.\n",
    "\n",
    "The dataset has no missing values and all features are numeric other than the target feature (which is binary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c860516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6efecba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_radius</th>\n",
       "      <th>mean_texture</th>\n",
       "      <th>mean_perimeter</th>\n",
       "      <th>mean_area</th>\n",
       "      <th>mean_smoothness</th>\n",
       "      <th>mean_compactness</th>\n",
       "      <th>mean_concavity</th>\n",
       "      <th>mean_concave_points</th>\n",
       "      <th>mean_symmetry</th>\n",
       "      <th>mean_fractal_dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst_texture</th>\n",
       "      <th>worst_perimeter</th>\n",
       "      <th>worst_area</th>\n",
       "      <th>worst_smoothness</th>\n",
       "      <th>worst_compactness</th>\n",
       "      <th>worst_concavity</th>\n",
       "      <th>worst_concave_points</th>\n",
       "      <th>worst_symmetry</th>\n",
       "      <th>worst_fractal_dimension</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_radius  mean_texture  mean_perimeter  mean_area  mean_smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean_compactness  mean_concavity  mean_concave_points  mean_symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean_fractal_dimension  ...  worst_texture  worst_perimeter  worst_area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst_smoothness  worst_compactness  worst_concavity  worst_concave_points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst_symmetry  worst_fractal_dimension  diagnosis  \n",
       "0          0.4601                  0.11890          M  \n",
       "1          0.2750                  0.08902          M  \n",
       "2          0.3613                  0.08758          M  \n",
       "3          0.6638                  0.17300          M  \n",
       "4          0.2364                  0.07678          M  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer_df = pd.read_csv('data/breast_cancer_wisconsin.csv')\n",
    "cancer_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a4c348",
   "metadata": {},
   "source": [
    "## Partitioning Dataset into the Set of DEscriptive Features and Target Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ad926f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = cancer_df.drop(columns='diagnosis')\n",
    "target = cancer_df['diagnosis']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ef1fbc",
   "metadata": {},
   "source": [
    "## Encoding Target feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2f1e67",
   "metadata": {},
   "source": [
    "Keep that in mind that `scikit-learn` always requires all data to be numeric, so the target need to be encoded as 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b40beedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "target = preprocessing.LabelEncoder().fit_transform(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdb13eb",
   "metadata": {},
   "source": [
    "Note that the `LabelEncoder` labels in an alphabetical order. That is, \"B\" is labeled as 0 whereas \"M\" as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71b10c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([357, 212], dtype=int64))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(target, return_counts= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadfb293",
   "metadata": {},
   "source": [
    "## Scaling Descriptive Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83230e8",
   "metadata": {},
   "source": [
    "Its always a good idea to scale your descriptive features before fitting any models. here, we use the \"min-max scaling\" so that each descriptive feature is scaled to be between 0 and 1. In the rest we work with scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42f150c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = preprocessing.MinMaxScaler().fit_transform(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a015a973",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52103744, 0.0226581 , 0.54598853, 0.36373277, 0.59375282,\n",
       "       0.7920373 , 0.70313964, 0.73111332, 0.68636364, 0.60551811,\n",
       "       0.35614702, 0.12046941, 0.3690336 , 0.27381126, 0.15929565,\n",
       "       0.35139844, 0.13568182, 0.30062512, 0.31164518, 0.18304244,\n",
       "       0.62077552, 0.14152452, 0.66831017, 0.45069799, 0.60113584,\n",
       "       0.61929156, 0.56861022, 0.91202749, 0.59846245, 0.41886396])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data[0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1e05d6",
   "metadata": {},
   "source": [
    "## Spliting Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3717fd",
   "metadata": {},
   "source": [
    "We split the descriptive features and the target feature into a `Training set` and  a `Test Set` by a ratio of 70:30. That is, we use 70% of the data to build our classifiers and evaluate their performance on the remaining 30% of the data. This is to ensure that we measure model performance on unseen data in order to avoid overfitting. We also set a random state value so that we can replicate our results later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d44cfd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "D_train, D_test, t_train, t_test = train_test_split(Data,\n",
    "                                                   target,\n",
    "                                                   test_size=0.3,\n",
    "                                                   random_state=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd57f479",
   "metadata": {},
   "source": [
    "## Fitting a Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e08d232",
   "metadata": {},
   "source": [
    "Let's fit a nearest neighbor classifier with 5 neighbors using the Euclidean distance. We fit the model on the train data and evaluate its performance on the test data.\n",
    "\n",
    "Below, the `score` method returns the accuracy of the classifier on the test data. Accuracy is defined as the ratio of correctly predicted observations to the total number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d454bf73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9707602339181286"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5, p=2) #p=1 is Manhattan Distance whether p=2 is Euclidean\n",
    "knn_classifier.fit(D_train,t_train)\n",
    "knn_classifier.score(D_test,t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87fa3e0",
   "metadata": {},
   "source": [
    "If you would like to see which parameters are available for a classifier, just type the name of the classifier followed by a question mark, e.g. \"KNeighborsClassifier?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6831baaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNeighborsClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2203dd4f",
   "metadata": {},
   "source": [
    "## Fitting a Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef7bfb4",
   "metadata": {},
   "source": [
    "Let's fit a decision tree classifier with the entropy split criterion and a maximum depth of 4 on the train data, and then evaluate its performance on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41b425c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DecisionTreeClassifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d5c271e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9239766081871345"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_classifier = DecisionTreeClassifier(criterion='entropy', max_depth=4)\n",
    "dt_classifier.fit(D_train,t_train)\n",
    "dt_classifier.score(D_test,t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18596c19",
   "metadata": {},
   "source": [
    "## Fitting a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a2778c",
   "metadata": {},
   "source": [
    "An ensemble method is a collection of many sub-classifiers. The final outcome is determined by a majority voting of the sub-classifiers. Random forest classifier is a popular ensemble method based on the idea of \"bagging\" where the sub-classifiers are decision trees. Let's fit a random forest classifier with 100 decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90c00f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9415204678362573"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RandomForestClassifier?\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100)\n",
    "rf_classifier.fit(D_train,t_train)\n",
    "rf_classifier.score(D_test,t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243cf3c0",
   "metadata": {},
   "source": [
    "## Fitting a Gaussian Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17435c7e",
   "metadata": {},
   "source": [
    "Another model we would like to fit to the breast cancer dataset is the Gaussian Naive Bayes classifier with a variance smoothing value of  $10^−3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "897ce847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.935672514619883"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_classifier = GaussianNB(var_smoothing=10**(-3))\n",
    "nb_classifier.fit(D_train, t_train)\n",
    "nb_classifier.score(D_test, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da38285b",
   "metadata": {},
   "source": [
    "## Fitting a Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e227a7",
   "metadata": {},
   "source": [
    "One last model we fit is the SVM with all the default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97988a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9883040935672515"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_classifier = SVC()\n",
    "svm_classifier.fit(D_train, t_train)\n",
    "svm_classifier.score(D_test, t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab104f58",
   "metadata": {},
   "source": [
    "## Making Predictions with a Fitted Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f29d517",
   "metadata": {},
   "source": [
    "Once a model is built, a prediction can be made using the predict method of the fitted classifier.\n",
    "\n",
    "For example, suppose we would like to use the fitted nearest neighbor classifier as our model, and we would like to find out the model's prediction for the first three rows in the input data. Of course, we already know the labels of these rows (which are all malignant), so this is just to illustrate how you would make a prediction for a new observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8279d5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.52103744 0.0226581  0.54598853 0.36373277 0.59375282 0.7920373\n",
      "  0.70313964 0.73111332 0.68636364 0.60551811 0.35614702 0.12046941\n",
      "  0.3690336  0.27381126 0.15929565 0.35139844 0.13568182 0.30062512\n",
      "  0.31164518 0.18304244 0.62077552 0.14152452 0.66831017 0.45069799\n",
      "  0.60113584 0.61929156 0.56861022 0.91202749 0.59846245 0.41886396]\n",
      " [0.64314449 0.27257355 0.61578329 0.50159067 0.28987993 0.18176799\n",
      "  0.20360825 0.34875746 0.37979798 0.14132266 0.15643672 0.08258929\n",
      "  0.12444047 0.12565979 0.11938675 0.08132304 0.0469697  0.25383595\n",
      "  0.08453875 0.0911101  0.60690146 0.30357143 0.53981772 0.43521431\n",
      "  0.34755332 0.15456336 0.19297125 0.63917526 0.23358959 0.22287813]\n",
      " [0.60149557 0.3902604  0.59574321 0.44941676 0.51430893 0.4310165\n",
      "  0.46251172 0.63568588 0.50959596 0.21124684 0.22962158 0.09430251\n",
      "  0.18037035 0.16292179 0.15083115 0.2839547  0.09676768 0.38984656\n",
      "  0.20569032 0.12700551 0.55638563 0.36007463 0.50844166 0.37450845\n",
      "  0.48358978 0.38537513 0.35974441 0.83505155 0.40370589 0.21343303]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_obs = Data[0:3]\n",
    "print(new_obs)\n",
    "knn_classifier.predict(new_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec92c5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739127a4",
   "metadata": {},
   "source": [
    "The model's prediction for these three rows is that they are all \"1\", that is, they are all \"malignant\". Thus, in this particular case, we observe that the model correctly predicts the first three rows in the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa24d248",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4730081",
   "metadata": {},
   "source": [
    "This tutorial illustrates that Python and Scikit-Learn together provide a unified interface to model fitting and evaluation and they greatly simplify the machine learning workflow.\n",
    "\n",
    "Of course, there is a whole lot more to supervised machine learning than what is shown in here, such as\n",
    "\n",
    "1. Other classification algorithms\n",
    "2. Solving prediction problems where the target feature is numeric (a.k.a. regression problems)\n",
    "3. Using other model performance metrics (e.g., precision, recall, mean squared error for regression, etc.)\n",
    "4. More sophisticated model performance assessment methods (such as cross-validation)\n",
    "5. How model parameters can be optimized (also known as hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e390e00d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
