{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c864ab",
   "metadata": {},
   "source": [
    "# SK3: Cross-Validation and Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4685de7",
   "metadata": {},
   "source": [
    "## Learning Objective\n",
    "- Implement various cross-validation strategies\n",
    "- Perform grid search to indentify optimal hyperparameter values.\n",
    "\n",
    "As in Part 1, we shall use the following datasets for regression, binary, and multiclass\n",
    "classification problems.\n",
    "1. `Breast Cancer Wiscons` in Data. The target feature is binary, i.e., if a cancer diagnosis is\n",
    "\"malignant\" or \"benign\"\n",
    "2. `Boston Housing` Data. The target feature is continuous. The target is house prices in Boston\n",
    "in 1970's.\n",
    "3. `Wine` Data. The target feature is multiclass. It consists of three types of wines in Italy.\n",
    "\n",
    "We use KNN, DT, and NB models to illustrate how cross-validation is used to tune\n",
    "hyperparameters of a machine learning algorithm via grid search by going through the Breast\n",
    "Cancer Data and Boston Housing Data. We will leave Wine Data and other machine learning\n",
    "models as exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360e46a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade altair\n",
    "# !pip install vega vega_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18abfec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RendererRegistry.enable('html')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "alt.renderers.enable('html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6bb4fa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "cancer_df = load_breast_cancer()\n",
    "Data,target = cancer_df.data, cancer_df.target\n",
    "\n",
    "Data = preprocessing.MinMaxScaler().fit_transform(Data)\n",
    "\n",
    "# target is already encoded, but we need to reverse the labels so that\n",
    "# malignant is the positive class\n",
    "target = np.where(target==0,1,0)\n",
    "\n",
    "D_train, D_test, t_train, t_test = train_test_split(Data, target,\n",
    "                                                    test_size=0.3,\n",
    "                                                   random_state=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f414e8",
   "metadata": {},
   "source": [
    "## Nearest Neighbor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c22f05b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=1,p=2)\n",
    "knn_classifier.fit(D_train, t_train)\n",
    "knn_classifier.score(D_test,t_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c925af",
   "metadata": {},
   "source": [
    "The 1-NN classifier yields an accuracy score of around 94.7%. So, how can we improve this\n",
    "score? One way is to search the set of \"hyperparameters\" which produces the highest accuracy\n",
    "score. For a nearest neighbor model, the hyperparameters are as follows:\n",
    "- Number of neighbors.\n",
    "- Metric: Manhattan (p=1), Euclidean (p=2) or Minkowski (any p larger than 2). Technically,\n",
    "p=1 and p=2 are also Minkowski metrics, but in this notebook, we shall adopt the\n",
    "convention that the Minkowski metric corresponds to $p â‰¥ 3$.\n",
    "\n",
    "To search for the \"best\" set of hyperparameters, popular approaches are as follows:\n",
    "- Random search: As its name suggests, it randomly selects the hyperparameter set to train models.\n",
    "- Bayesian search: It is beyond the scope of this course. So we shall not cover it here.\n",
    "- Grid search\n",
    "\n",
    "Grid search is the most common approach. It exhaustively searches through all possible\n",
    "combinations of hyperparameters during training the phase. For example, consider a KNN\n",
    "model. We can specify a grid of number of neighbors (K = 1, 2, 3) and two metrics (p=1, 2). The\n",
    "grid search starts training a model of K = 1 and p=1 and calculates its accuracy score. Then it\n",
    "moves to train models of (K = 2, p = 1), (K = 3, p = 1), (K = 1, p = 2), ..., and (K = 3, p = 2) and\n",
    "obtain their score values. Based on the accuracy scores, the grid search will rank the models\n",
    "and determine the set of hyperparameter values that give the highest accuracy score.\n",
    "\n",
    "Before we proceed further, we shall cover other cross-validation (CV) methods since tuning\n",
    "hyperparameters via grid search is usually cross-validated to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4a9f03",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "Two popular options for cross-validation are 5-fold and 10-fold. In 5-fold cross-validation, for\n",
    "instance, the entire dataset is partitioned into 5 equal-sized chunks. The first four chunks are\n",
    "used for training and the 5-th chunk is used for testing. Next, all the chunks other than the 4-th\n",
    "chunk are used for training and the 4-th chunk is used for testing, and so on. In the last iteration,\n",
    "all the chunks other than the 1-st chunk are used for training and the 1-st chunk is used for\n",
    "testing. The final step is to take the average of these 5 test accuracies and report it as the\n",
    "overall cross-validation accuracy. Please see the figure below for an illustration of a 10-fold\n",
    "cross-validation (source: karlrosaen.com) . Please refer to Chapter 8 in the textbook for more\n",
    "information.\n",
    "\n",
    "<img src=http://karlrosaen.com/ml/learning-log/2016-06-20/k-fold-diagram.png width=\"600\">\n",
    "\n",
    "In contrast to hold-out-sampling, cross-validation is usually the preferred option due to the\n",
    "following two reasons:\n",
    "- Sometimes there is just not enough data for a hold-out-sampling.\n",
    "- Cross-validation reduces the risk of what is called \"lucky split\" where the difficult instances\n",
    "are put in the training partition and the easy instances are put in the test partition.\n",
    "A downside of cross-validation is that it apparently requires more computer time. Also, if it\n",
    "happens to be the case that there is a good amount of data available already (say millions of\n",
    "rows), then the risk of \"lucky split\" diminishes and hold-out-sampling can be preferred. Another\n",
    "extension of cross-validation is repeated cross-validation (say 3 times) where data is partitioned\n",
    "into 5 equal-sized chunks multiple times and the cross-validation procedure is repeated, each\n",
    "time with a different partitioning of data per repeatition.\n",
    "\n",
    "We can perform -fold cross-validation by calling the `KFold` function imported from\n",
    "sklearn.model_selection module. It randomly splits the full dataset into K subsets or\n",
    "\"folds\". Then it trains the model on K-1 folds and evaluates the model against the remaining\n",
    "fold. This process is repeated exactly K times where each time a different fold is used for\n",
    "testing.\n",
    "Other cross-validation variants from scikit-learn are as follows:\n",
    "- `model_selection.RepeatedKFold()`: Repeated K-Fold cross-validator\n",
    "- `model_selection.RepeatedSaratifiedKFold()` : Repeated Stratified K-Fold cross-\n",
    "validator\n",
    "- `model_selection.StratifiedKFold()`: Stratified K-Fold cross-validator\n",
    "- `model_selection.LeaveOneOut()` : Leave One Out cross-validator\n",
    "To learn more about cross-validators, please refer to scikit-learn documentation.\n",
    "\n",
    "**Refresher questions**\n",
    "1. What are the disadvantages of a simple test/ train split?\n",
    "2. Can you tell the difference between the cross-validators above?\n",
    "\n",
    "In the following example, we illustrate how we can conduct a stratified 5-fold (n splits = 5)\n",
    "cross-validation with 3 repetitions (n _repeats = 3 ) using the RepeatedStratifiedKFold\n",
    "function. Since the target labels have fewer malignant labels than benign, stratification\n",
    "ensures that the proportion of the two labels in both train and test sets are the same as the\n",
    "proportion in the full dataset in each cross-validation repetition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8827a7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "cv_method = RepeatedStratifiedKFold(n_splits=5,\n",
    "                                   n_repeats=3,\n",
    "                                   random_state=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77996136",
   "metadata": {},
   "source": [
    "## KNN HyperParameter and VIsualisation\n",
    "\n",
    "It's hyperparameter tuning time, First, we need to define a dictonary of KNN parameters for the grid search. Here, we will consider K values between 3 and 7 and $p$ values of 1(Manhattan), 2(Euclidean), and 5(Minkowski)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daf2a91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_KNN = {'n_neighbors': [1,2,3,4,5,6,7],\n",
    "             'p':[1,2,5]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042ac757",
   "metadata": {},
   "source": [
    "Second, we pass the `KNeighborsClassifier()` and `KNN_params` as the model and the\n",
    "parameter dictonary into the `GridSearchCV` function. In addition, we include the repeated stratified CV method we defined previously `(cv=cv method)`. Also, we tell sklearn which metric to optimize, which is accuracy in our example `(scoring='accuracy',refit='accuracy)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5406c3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gs_KNN = GridSearchCV(estimator=KNeighborsClassifier(),\n",
    "                     param_grid=params_KNN,\n",
    "                     cv=cv_method,\n",
    "                     verbose=1,\n",
    "                     scoring='accuracy',\n",
    "                     return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143f492a",
   "metadata": {},
   "source": [
    "The last step is to fit a KNN model using the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7097c2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 21 candidates, totalling 315 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=RepeatedStratifiedKFold(n_repeats=3, n_splits=5, random_state=999),\n",
       "             estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7], 'p': [1, 2, 5]},\n",
       "             return_train_score=True, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_KNN.fit(Data,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1703adc",
   "metadata": {},
   "source": [
    " ----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9e04c8",
   "metadata": {},
   "source": [
    "To get the best parameter values, we call the `best_params_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df6becb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 3, 'p': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_KNN.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e122d0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
